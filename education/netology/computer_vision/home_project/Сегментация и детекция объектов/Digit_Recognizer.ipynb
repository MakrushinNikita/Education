{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhYhvF2m8lfL"
      },
      "source": [
        "## Digit Recognizer\n",
        "https://www.kaggle.com/c/digit-recognizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "TCSXiUcqm8vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade catboost"
      ],
      "metadata": {
        "id": "_tLCIzDMoaS-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "collapsed": true,
        "id": "kjzeq3Sz8lfP"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import catboost\n",
        "import tensorflow as tf\n",
        "from catboost import CatBoostClassifier, cv, Pool\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, CategoricalNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwlD8pbL8lfQ"
      },
      "source": [
        "## Загружаем исходные данные"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = fetch_openml('mnist_784')\n",
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int')"
      ],
      "metadata": {
        "id": "4qvStad-ALG1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Приминение PCA"
      ],
      "metadata": {
        "id": "A_I9qSJYprbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_components = 128  # Количество главных компонент\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "nQS2MtX6prJm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Разделение на тренировочные и тестовые данные"
      ],
      "metadata": {
        "id": "_Tpk9y4zqe57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = len(X)\n",
        "n_train = int(0.8 * n_samples)\n",
        "X_train, X_test = X_pca[:n_train], X_pca[n_train:]\n",
        "y_train, y_test = y[:n_train], y[n_train:]"
      ],
      "metadata": {
        "id": "0JHayobnqgdX"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Построение модели Navie Bayes"
      ],
      "metadata": {
        "id": "TcZCZYLO-rXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = GaussianNB()"
      ],
      "metadata": {
        "id": "bTHxn8BZAvGw"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_train,y_train)\n",
        "y_predicted = clf.predict(X_test)\n",
        "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_predicted)*100))\n",
        "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_predicted, labels=range(0,10))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPsK1bF0-bn8",
        "outputId": "bc7dd8e4-a919-4b9c-e94d-4ffca087f045"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 87.62142857142857 %\n",
            "Classification Report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      1373\n",
            "           1       0.98      0.95      0.96      1569\n",
            "           2       0.75      0.86      0.80      1430\n",
            "           3       0.82      0.87      0.84      1413\n",
            "           4       0.89      0.85      0.87      1376\n",
            "           5       0.83      0.84      0.84      1253\n",
            "           6       0.94      0.91      0.92      1339\n",
            "           7       0.93      0.84      0.88      1483\n",
            "           8       0.86      0.87      0.87      1365\n",
            "           9       0.83      0.84      0.83      1399\n",
            "\n",
            "    accuracy                           0.88     14000\n",
            "   macro avg       0.88      0.88      0.88     14000\n",
            "weighted avg       0.88      0.88      0.88     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(X_pca, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "EvQdOIx4x8Tm",
        "outputId": "f1dc5838-bef0-47ad-e194-816491dd3c9e"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Построение модели LogisticRegression"
      ],
      "metadata": {
        "id": "HEbprj7Olaaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr = LogisticRegression()"
      ],
      "metadata": {
        "id": "aFMxNQyHlg8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr.fit(X_train,y_train)\n",
        "y_predicted = clf_lr.predict(X_test)\n",
        "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_predicted)*100))\n",
        "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_predicted, labels=range(0,10))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwiHT5Sclg8m",
        "outputId": "11401017-e73d-4018-8fdf-8b324b9f36fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 92.41428571428571 %\n",
            "Classification Report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96      1373\n",
            "           1       0.95      0.98      0.96      1569\n",
            "           2       0.94      0.91      0.92      1430\n",
            "           3       0.91      0.91      0.91      1413\n",
            "           4       0.92      0.94      0.93      1376\n",
            "           5       0.91      0.86      0.88      1253\n",
            "           6       0.94      0.96      0.95      1339\n",
            "           7       0.93      0.94      0.93      1483\n",
            "           8       0.89      0.86      0.87      1365\n",
            "           9       0.91      0.91      0.91      1399\n",
            "\n",
            "    accuracy                           0.92     14000\n",
            "   macro avg       0.92      0.92      0.92     14000\n",
            "weighted avg       0.92      0.92      0.92     14000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_lr.fit(X_pca, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "u_rFiOfJlg8m",
        "outputId": "c04d8b12-fd84-4601-dcb6-be8442ab136d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Построение модели SVC"
      ],
      "metadata": {
        "id": "Nfy32WqZogGu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svc = LinearSVC()"
      ],
      "metadata": {
        "id": "Dc-5Xu6OouMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svc.fit(X_train,y_train)\n",
        "y_predicted = clf_svc.predict(X_test)\n",
        "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_predicted)*100))\n",
        "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_predicted, labels=range(0,10))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TxhVc_fouI9",
        "outputId": "ecfa5c05-fb0a-4739-d4b8-979d17912785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 71.72857142857143 %\n",
            "Classification Report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.85      0.77      1373\n",
            "           1       0.88      0.95      0.91      1569\n",
            "           2       0.86      0.63      0.73      1430\n",
            "           3       0.65      0.58      0.61      1413\n",
            "           4       0.72      0.62      0.67      1376\n",
            "           5       0.71      0.39      0.50      1253\n",
            "           6       0.75      0.85      0.80      1339\n",
            "           7       0.70      0.86      0.77      1483\n",
            "           8       0.56      0.80      0.66      1365\n",
            "           9       0.69      0.58      0.63      1399\n",
            "\n",
            "    accuracy                           0.72     14000\n",
            "   macro avg       0.72      0.71      0.71     14000\n",
            "weighted avg       0.73      0.72      0.71     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_svc.fit(X_pca, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "HWAlBN5WotmD",
        "outputId": "b1c985fa-9fc0-47ab-9b87-666e98999ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Построение модели RandomForestClassifier"
      ],
      "metadata": {
        "id": "-2tw_NNis1FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rfc = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "d55vQY96tIVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rfc.fit(X_train,y_train)\n",
        "y_predicted = clf_rfc.predict(X_test)\n",
        "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_predicted)*100))\n",
        "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_predicted, labels=range(0,10))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVVvKGUwtIHh",
        "outputId": "bfe3eb8d-4575-4439-cfd2-072e14719463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 94.78571428571428 %\n",
            "Classification Report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1373\n",
            "           1       0.98      0.98      0.98      1569\n",
            "           2       0.95      0.93      0.94      1430\n",
            "           3       0.92      0.95      0.94      1413\n",
            "           4       0.93      0.95      0.94      1376\n",
            "           5       0.94      0.92      0.93      1253\n",
            "           6       0.96      0.97      0.97      1339\n",
            "           7       0.96      0.95      0.95      1483\n",
            "           8       0.93      0.91      0.92      1365\n",
            "           9       0.94      0.92      0.93      1399\n",
            "\n",
            "    accuracy                           0.95     14000\n",
            "   macro avg       0.95      0.95      0.95     14000\n",
            "weighted avg       0.95      0.95      0.95     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf_rfc.fit(X_pca, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ERUKdfeJtLXK",
        "outputId": "8e91f290-208d-4213-97d6-784b60cd1653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Построение модели CatBoost"
      ],
      "metadata": {
        "id": "akRIXNIfnlwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=42)"
      ],
      "metadata": {
        "id": "h58abCw098Mj"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_train = catboost.Pool(X_train, y_train)\n",
        "D_val = catboost.Pool(X_val, y_val)\n",
        "\n",
        "params = dict()\n",
        "params['learning_rate'] = 0.10\n",
        "params['depth'] = 6\n",
        "params['l2_leaf_reg'] = 4\n",
        "params['rsm'] = 1.0\n",
        "\n",
        "model = CatBoostClassifier(iterations=500,\n",
        "                           learning_rate=params['learning_rate'],\n",
        "                           depth=int(params['depth']),\n",
        "                           loss_function='MultiClass',\n",
        "                           use_best_model=True,\n",
        "                           eval_metric='MultiClass',\n",
        "                           l2_leaf_reg=params['l2_leaf_reg'],\n",
        "                           random_seed=42,\n",
        "                           verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "d9MvadOWwlSd"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(D_train, eval_set=D_val, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWAZ-MESsyG-",
        "outputId": "44fd833e-e460-4ac8-f245-3d1ce7bf7d6c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 1.9826790\ttest: 1.9848378\tbest: 1.9848378 (0)\ttotal: 1.51s\tremaining: 12m 33s\n",
            "1:\tlearn: 1.7824647\ttest: 1.7860825\tbest: 1.7860825 (1)\ttotal: 2.29s\tremaining: 9m 31s\n",
            "2:\tlearn: 1.6456508\ttest: 1.6494923\tbest: 1.6494923 (2)\ttotal: 3.09s\tremaining: 8m 31s\n",
            "3:\tlearn: 1.5328418\ttest: 1.5384094\tbest: 1.5384094 (3)\ttotal: 3.88s\tremaining: 8m 1s\n",
            "4:\tlearn: 1.4448750\ttest: 1.4502626\tbest: 1.4502626 (4)\ttotal: 4.66s\tremaining: 7m 41s\n",
            "5:\tlearn: 1.3633155\ttest: 1.3697081\tbest: 1.3697081 (5)\ttotal: 5.44s\tremaining: 7m 27s\n",
            "6:\tlearn: 1.2963222\ttest: 1.3036791\tbest: 1.3036791 (6)\ttotal: 6.22s\tremaining: 7m 17s\n",
            "7:\tlearn: 1.2422840\ttest: 1.2495052\tbest: 1.2495052 (7)\ttotal: 7.01s\tremaining: 7m 11s\n",
            "8:\tlearn: 1.1909427\ttest: 1.1986290\tbest: 1.1986290 (8)\ttotal: 7.8s\tremaining: 7m 5s\n",
            "9:\tlearn: 1.1443904\ttest: 1.1528887\tbest: 1.1528887 (9)\ttotal: 8.56s\tremaining: 6m 59s\n",
            "10:\tlearn: 1.1033664\ttest: 1.1120149\tbest: 1.1120149 (10)\ttotal: 9.34s\tremaining: 6m 55s\n",
            "11:\tlearn: 1.0652199\ttest: 1.0745857\tbest: 1.0745857 (11)\ttotal: 10.1s\tremaining: 6m 52s\n",
            "12:\tlearn: 1.0256265\ttest: 1.0350983\tbest: 1.0350983 (12)\ttotal: 10.9s\tremaining: 6m 49s\n",
            "13:\tlearn: 0.9917782\ttest: 1.0013947\tbest: 1.0013947 (13)\ttotal: 11.8s\tremaining: 6m 49s\n",
            "14:\tlearn: 0.9643362\ttest: 0.9743974\tbest: 0.9743974 (14)\ttotal: 13.2s\tremaining: 7m 6s\n",
            "15:\tlearn: 0.9382039\ttest: 0.9487324\tbest: 0.9487324 (15)\ttotal: 14.6s\tremaining: 7m 21s\n",
            "16:\tlearn: 0.9083280\ttest: 0.9190534\tbest: 0.9190534 (16)\ttotal: 15.4s\tremaining: 7m 17s\n",
            "17:\tlearn: 0.8829494\ttest: 0.8936984\tbest: 0.8936984 (17)\ttotal: 16.2s\tremaining: 7m 13s\n",
            "18:\tlearn: 0.8533446\ttest: 0.8644270\tbest: 0.8644270 (18)\ttotal: 17s\tremaining: 7m 10s\n",
            "19:\tlearn: 0.8284400\ttest: 0.8396899\tbest: 0.8396899 (19)\ttotal: 18.2s\tremaining: 7m 16s\n",
            "20:\tlearn: 0.8106747\ttest: 0.8218056\tbest: 0.8218056 (20)\ttotal: 19.6s\tremaining: 7m 26s\n",
            "21:\tlearn: 0.7923868\ttest: 0.8036283\tbest: 0.8036283 (21)\ttotal: 20.8s\tremaining: 7m 31s\n",
            "22:\tlearn: 0.7731694\ttest: 0.7848170\tbest: 0.7848170 (22)\ttotal: 22.1s\tremaining: 7m 37s\n",
            "23:\tlearn: 0.7557475\ttest: 0.7674443\tbest: 0.7674443 (23)\ttotal: 24.6s\tremaining: 8m 8s\n",
            "24:\tlearn: 0.7356370\ttest: 0.7476038\tbest: 0.7476038 (24)\ttotal: 27.9s\tremaining: 8m 49s\n",
            "25:\tlearn: 0.7225798\ttest: 0.7349692\tbest: 0.7349692 (25)\ttotal: 29.7s\tremaining: 9m\n",
            "26:\tlearn: 0.7069069\ttest: 0.7197622\tbest: 0.7197622 (26)\ttotal: 31.3s\tremaining: 9m 7s\n",
            "27:\tlearn: 0.6920201\ttest: 0.7052087\tbest: 0.7052087 (27)\ttotal: 33s\tremaining: 9m 16s\n",
            "28:\tlearn: 0.6771147\ttest: 0.6903929\tbest: 0.6903929 (28)\ttotal: 34.1s\tremaining: 9m 14s\n",
            "29:\tlearn: 0.6640031\ttest: 0.6772958\tbest: 0.6772958 (29)\ttotal: 34.9s\tremaining: 9m 7s\n",
            "30:\tlearn: 0.6517744\ttest: 0.6651020\tbest: 0.6651020 (30)\ttotal: 35.7s\tremaining: 9m\n",
            "31:\tlearn: 0.6386275\ttest: 0.6522221\tbest: 0.6522221 (31)\ttotal: 36.5s\tremaining: 8m 53s\n",
            "32:\tlearn: 0.6280397\ttest: 0.6417625\tbest: 0.6417625 (32)\ttotal: 37.3s\tremaining: 8m 47s\n",
            "33:\tlearn: 0.6147243\ttest: 0.6285988\tbest: 0.6285988 (33)\ttotal: 38.4s\tremaining: 8m 46s\n",
            "34:\tlearn: 0.6015295\ttest: 0.6154662\tbest: 0.6154662 (34)\ttotal: 39.9s\tremaining: 8m 50s\n",
            "35:\tlearn: 0.5912427\ttest: 0.6055656\tbest: 0.6055656 (35)\ttotal: 41s\tremaining: 8m 48s\n",
            "36:\tlearn: 0.5799597\ttest: 0.5944230\tbest: 0.5944230 (36)\ttotal: 41.8s\tremaining: 8m 43s\n",
            "37:\tlearn: 0.5721240\ttest: 0.5869330\tbest: 0.5869330 (37)\ttotal: 42.6s\tremaining: 8m 37s\n",
            "38:\tlearn: 0.5635385\ttest: 0.5784893\tbest: 0.5784893 (38)\ttotal: 43.4s\tremaining: 8m 32s\n",
            "39:\tlearn: 0.5543957\ttest: 0.5693013\tbest: 0.5693013 (39)\ttotal: 44.2s\tremaining: 8m 28s\n",
            "40:\tlearn: 0.5450083\ttest: 0.5602028\tbest: 0.5602028 (40)\ttotal: 45s\tremaining: 8m 23s\n",
            "41:\tlearn: 0.5362390\ttest: 0.5514203\tbest: 0.5514203 (41)\ttotal: 45.7s\tremaining: 8m 18s\n",
            "42:\tlearn: 0.5277920\ttest: 0.5432875\tbest: 0.5432875 (42)\ttotal: 46.5s\tremaining: 8m 14s\n",
            "43:\tlearn: 0.5196758\ttest: 0.5353289\tbest: 0.5353289 (43)\ttotal: 47.6s\tremaining: 8m 13s\n",
            "44:\tlearn: 0.5118222\ttest: 0.5277754\tbest: 0.5277754 (44)\ttotal: 49.1s\tremaining: 8m 16s\n",
            "45:\tlearn: 0.5045190\ttest: 0.5208197\tbest: 0.5208197 (45)\ttotal: 50.3s\tremaining: 8m 16s\n",
            "46:\tlearn: 0.4969782\ttest: 0.5134861\tbest: 0.5134861 (46)\ttotal: 51.4s\tremaining: 8m 15s\n",
            "47:\tlearn: 0.4874331\ttest: 0.5039881\tbest: 0.5039881 (47)\ttotal: 52.9s\tremaining: 8m 18s\n",
            "48:\tlearn: 0.4815339\ttest: 0.4982378\tbest: 0.4982378 (48)\ttotal: 54s\tremaining: 8m 16s\n",
            "49:\tlearn: 0.4752300\ttest: 0.4922481\tbest: 0.4922481 (49)\ttotal: 54.7s\tremaining: 8m 12s\n",
            "50:\tlearn: 0.4680393\ttest: 0.4851532\tbest: 0.4851532 (50)\ttotal: 55.5s\tremaining: 8m 8s\n",
            "51:\tlearn: 0.4615129\ttest: 0.4788966\tbest: 0.4788966 (51)\ttotal: 56.3s\tremaining: 8m 5s\n",
            "52:\tlearn: 0.4549080\ttest: 0.4724623\tbest: 0.4724623 (52)\ttotal: 57.1s\tremaining: 8m 1s\n",
            "53:\tlearn: 0.4489882\ttest: 0.4666186\tbest: 0.4666186 (53)\ttotal: 57.9s\tremaining: 7m 58s\n",
            "54:\tlearn: 0.4423867\ttest: 0.4605081\tbest: 0.4605081 (54)\ttotal: 58.7s\tremaining: 7m 54s\n",
            "55:\tlearn: 0.4376171\ttest: 0.4559185\tbest: 0.4559185 (55)\ttotal: 59.5s\tremaining: 7m 51s\n",
            "56:\tlearn: 0.4330361\ttest: 0.4514426\tbest: 0.4514426 (56)\ttotal: 1m\tremaining: 7m 48s\n",
            "57:\tlearn: 0.4276497\ttest: 0.4465706\tbest: 0.4465706 (57)\ttotal: 1m 1s\tremaining: 7m 45s\n",
            "58:\tlearn: 0.4227558\ttest: 0.4415655\tbest: 0.4415655 (58)\ttotal: 1m 1s\tremaining: 7m 42s\n",
            "59:\tlearn: 0.4174749\ttest: 0.4364688\tbest: 0.4364688 (59)\ttotal: 1m 2s\tremaining: 7m 39s\n",
            "60:\tlearn: 0.4117605\ttest: 0.4313495\tbest: 0.4313495 (60)\ttotal: 1m 3s\tremaining: 7m 36s\n",
            "61:\tlearn: 0.4079209\ttest: 0.4274569\tbest: 0.4274569 (61)\ttotal: 1m 4s\tremaining: 7m 36s\n",
            "62:\tlearn: 0.4049380\ttest: 0.4246249\tbest: 0.4246249 (62)\ttotal: 1m 6s\tremaining: 7m 38s\n",
            "63:\tlearn: 0.4002690\ttest: 0.4199696\tbest: 0.4199696 (63)\ttotal: 1m 7s\tremaining: 7m 37s\n",
            "64:\tlearn: 0.3960083\ttest: 0.4159565\tbest: 0.4159565 (64)\ttotal: 1m 7s\tremaining: 7m 34s\n",
            "65:\tlearn: 0.3919264\ttest: 0.4119563\tbest: 0.4119563 (65)\ttotal: 1m 8s\tremaining: 7m 31s\n",
            "66:\tlearn: 0.3885635\ttest: 0.4088547\tbest: 0.4088547 (66)\ttotal: 1m 9s\tremaining: 7m 28s\n",
            "67:\tlearn: 0.3835993\ttest: 0.4041977\tbest: 0.4041977 (67)\ttotal: 1m 10s\tremaining: 7m 26s\n",
            "68:\tlearn: 0.3810649\ttest: 0.4018244\tbest: 0.4018244 (68)\ttotal: 1m 11s\tremaining: 7m 23s\n",
            "69:\tlearn: 0.3767461\ttest: 0.3972581\tbest: 0.3972581 (69)\ttotal: 1m 11s\tremaining: 7m 20s\n",
            "70:\tlearn: 0.3734615\ttest: 0.3941092\tbest: 0.3941092 (70)\ttotal: 1m 12s\tremaining: 7m 18s\n",
            "71:\tlearn: 0.3702795\ttest: 0.3911618\tbest: 0.3911618 (71)\ttotal: 1m 13s\tremaining: 7m 16s\n",
            "72:\tlearn: 0.3673482\ttest: 0.3883490\tbest: 0.3883490 (72)\ttotal: 1m 14s\tremaining: 7m 13s\n",
            "73:\tlearn: 0.3625983\ttest: 0.3838418\tbest: 0.3838418 (73)\ttotal: 1m 14s\tremaining: 7m 11s\n",
            "74:\tlearn: 0.3592568\ttest: 0.3805697\tbest: 0.3805697 (74)\ttotal: 1m 15s\tremaining: 7m 8s\n",
            "75:\tlearn: 0.3558921\ttest: 0.3776873\tbest: 0.3776873 (75)\ttotal: 1m 16s\tremaining: 7m 6s\n",
            "76:\tlearn: 0.3527222\ttest: 0.3745735\tbest: 0.3745735 (76)\ttotal: 1m 17s\tremaining: 7m 7s\n",
            "77:\tlearn: 0.3504123\ttest: 0.3723278\tbest: 0.3723278 (77)\ttotal: 1m 19s\tremaining: 7m 9s\n",
            "78:\tlearn: 0.3477495\ttest: 0.3698849\tbest: 0.3698849 (78)\ttotal: 1m 20s\tremaining: 7m 7s\n",
            "79:\tlearn: 0.3439900\ttest: 0.3663417\tbest: 0.3663417 (79)\ttotal: 1m 20s\tremaining: 7m 5s\n",
            "80:\tlearn: 0.3413685\ttest: 0.3639425\tbest: 0.3639425 (80)\ttotal: 1m 21s\tremaining: 7m 2s\n",
            "81:\tlearn: 0.3393381\ttest: 0.3623268\tbest: 0.3623268 (81)\ttotal: 1m 22s\tremaining: 7m\n",
            "82:\tlearn: 0.3360921\ttest: 0.3593584\tbest: 0.3593584 (82)\ttotal: 1m 23s\tremaining: 6m 58s\n",
            "83:\tlearn: 0.3336568\ttest: 0.3570638\tbest: 0.3570638 (83)\ttotal: 1m 24s\tremaining: 6m 56s\n",
            "84:\tlearn: 0.3306030\ttest: 0.3543625\tbest: 0.3543625 (84)\ttotal: 1m 24s\tremaining: 6m 54s\n",
            "85:\tlearn: 0.3283555\ttest: 0.3522952\tbest: 0.3522952 (85)\ttotal: 1m 25s\tremaining: 6m 52s\n",
            "86:\tlearn: 0.3264429\ttest: 0.3506278\tbest: 0.3506278 (86)\ttotal: 1m 26s\tremaining: 6m 50s\n",
            "87:\tlearn: 0.3241537\ttest: 0.3485664\tbest: 0.3485664 (87)\ttotal: 1m 27s\tremaining: 6m 48s\n",
            "88:\tlearn: 0.3222535\ttest: 0.3468768\tbest: 0.3468768 (88)\ttotal: 1m 27s\tremaining: 6m 46s\n",
            "89:\tlearn: 0.3196567\ttest: 0.3445105\tbest: 0.3445105 (89)\ttotal: 1m 28s\tremaining: 6m 44s\n",
            "90:\tlearn: 0.3171264\ttest: 0.3421973\tbest: 0.3421973 (90)\ttotal: 1m 29s\tremaining: 6m 42s\n",
            "91:\tlearn: 0.3154200\ttest: 0.3405860\tbest: 0.3405860 (91)\ttotal: 1m 30s\tremaining: 6m 43s\n",
            "92:\tlearn: 0.3133366\ttest: 0.3386266\tbest: 0.3386266 (92)\ttotal: 1m 32s\tremaining: 6m 44s\n",
            "93:\tlearn: 0.3107007\ttest: 0.3362059\tbest: 0.3362059 (93)\ttotal: 1m 33s\tremaining: 6m 42s\n",
            "94:\tlearn: 0.3086246\ttest: 0.3341996\tbest: 0.3341996 (94)\ttotal: 1m 33s\tremaining: 6m 40s\n",
            "95:\tlearn: 0.3067359\ttest: 0.3323860\tbest: 0.3323860 (95)\ttotal: 1m 34s\tremaining: 6m 38s\n",
            "96:\tlearn: 0.3047503\ttest: 0.3303837\tbest: 0.3303837 (96)\ttotal: 1m 35s\tremaining: 6m 36s\n",
            "97:\tlearn: 0.3024153\ttest: 0.3281846\tbest: 0.3281846 (97)\ttotal: 1m 36s\tremaining: 6m 35s\n",
            "98:\tlearn: 0.2997988\ttest: 0.3257073\tbest: 0.3257073 (98)\ttotal: 1m 37s\tremaining: 6m 33s\n",
            "99:\tlearn: 0.2979535\ttest: 0.3239407\tbest: 0.3239407 (99)\ttotal: 1m 37s\tremaining: 6m 31s\n",
            "100:\tlearn: 0.2963470\ttest: 0.3225894\tbest: 0.3225894 (100)\ttotal: 1m 38s\tremaining: 6m 29s\n",
            "101:\tlearn: 0.2946459\ttest: 0.3210267\tbest: 0.3210267 (101)\ttotal: 1m 39s\tremaining: 6m 28s\n",
            "102:\tlearn: 0.2931002\ttest: 0.3196164\tbest: 0.3196164 (102)\ttotal: 1m 40s\tremaining: 6m 26s\n",
            "103:\tlearn: 0.2915052\ttest: 0.3181559\tbest: 0.3181559 (103)\ttotal: 1m 40s\tremaining: 6m 24s\n",
            "104:\tlearn: 0.2896848\ttest: 0.3165536\tbest: 0.3165536 (104)\ttotal: 1m 41s\tremaining: 6m 22s\n",
            "105:\tlearn: 0.2871296\ttest: 0.3140176\tbest: 0.3140176 (105)\ttotal: 1m 42s\tremaining: 6m 21s\n",
            "106:\tlearn: 0.2847367\ttest: 0.3117788\tbest: 0.3117788 (106)\ttotal: 1m 44s\tremaining: 6m 22s\n",
            "107:\tlearn: 0.2833838\ttest: 0.3104161\tbest: 0.3104161 (107)\ttotal: 1m 45s\tremaining: 6m 22s\n",
            "108:\tlearn: 0.2815965\ttest: 0.3088131\tbest: 0.3088131 (108)\ttotal: 1m 46s\tremaining: 6m 20s\n",
            "109:\tlearn: 0.2795183\ttest: 0.3069113\tbest: 0.3069113 (109)\ttotal: 1m 46s\tremaining: 6m 19s\n",
            "110:\tlearn: 0.2775505\ttest: 0.3050769\tbest: 0.3050769 (110)\ttotal: 1m 47s\tremaining: 6m 17s\n",
            "111:\tlearn: 0.2756888\ttest: 0.3031508\tbest: 0.3031508 (111)\ttotal: 1m 48s\tremaining: 6m 16s\n",
            "112:\tlearn: 0.2736671\ttest: 0.3011921\tbest: 0.3011921 (112)\ttotal: 1m 49s\tremaining: 6m 14s\n",
            "113:\tlearn: 0.2723288\ttest: 0.3000641\tbest: 0.3000641 (113)\ttotal: 1m 50s\tremaining: 6m 12s\n",
            "114:\tlearn: 0.2711070\ttest: 0.2990226\tbest: 0.2990226 (114)\ttotal: 1m 50s\tremaining: 6m 11s\n",
            "115:\tlearn: 0.2690681\ttest: 0.2970244\tbest: 0.2970244 (115)\ttotal: 1m 51s\tremaining: 6m 9s\n",
            "116:\tlearn: 0.2677745\ttest: 0.2957569\tbest: 0.2957569 (116)\ttotal: 1m 52s\tremaining: 6m 8s\n",
            "117:\tlearn: 0.2666071\ttest: 0.2946791\tbest: 0.2946791 (117)\ttotal: 1m 53s\tremaining: 6m 6s\n",
            "118:\tlearn: 0.2656902\ttest: 0.2939875\tbest: 0.2939875 (118)\ttotal: 1m 53s\tremaining: 6m 4s\n",
            "119:\tlearn: 0.2648089\ttest: 0.2931548\tbest: 0.2931548 (119)\ttotal: 1m 54s\tremaining: 6m 3s\n",
            "120:\tlearn: 0.2628485\ttest: 0.2914036\tbest: 0.2914036 (120)\ttotal: 1m 55s\tremaining: 6m 2s\n",
            "121:\tlearn: 0.2611386\ttest: 0.2897403\tbest: 0.2897403 (121)\ttotal: 1m 57s\tremaining: 6m 3s\n",
            "122:\tlearn: 0.2594722\ttest: 0.2881828\tbest: 0.2881828 (122)\ttotal: 1m 58s\tremaining: 6m 2s\n",
            "123:\tlearn: 0.2583761\ttest: 0.2871104\tbest: 0.2871104 (123)\ttotal: 1m 59s\tremaining: 6m 1s\n",
            "124:\tlearn: 0.2576075\ttest: 0.2864300\tbest: 0.2864300 (124)\ttotal: 1m 59s\tremaining: 5m 59s\n",
            "125:\tlearn: 0.2556768\ttest: 0.2846655\tbest: 0.2846655 (125)\ttotal: 2m\tremaining: 5m 58s\n",
            "126:\tlearn: 0.2540397\ttest: 0.2830705\tbest: 0.2830705 (126)\ttotal: 2m 1s\tremaining: 5m 56s\n",
            "127:\tlearn: 0.2528243\ttest: 0.2819724\tbest: 0.2819724 (127)\ttotal: 2m 2s\tremaining: 5m 55s\n",
            "128:\tlearn: 0.2516661\ttest: 0.2810677\tbest: 0.2810677 (128)\ttotal: 2m 3s\tremaining: 5m 53s\n",
            "129:\tlearn: 0.2492775\ttest: 0.2788275\tbest: 0.2788275 (129)\ttotal: 2m 3s\tremaining: 5m 52s\n",
            "130:\tlearn: 0.2483548\ttest: 0.2781351\tbest: 0.2781351 (130)\ttotal: 2m 4s\tremaining: 5m 51s\n",
            "131:\tlearn: 0.2466159\ttest: 0.2765943\tbest: 0.2765943 (131)\ttotal: 2m 5s\tremaining: 5m 49s\n",
            "132:\tlearn: 0.2452683\ttest: 0.2755330\tbest: 0.2755330 (132)\ttotal: 2m 6s\tremaining: 5m 48s\n",
            "133:\tlearn: 0.2443876\ttest: 0.2746420\tbest: 0.2746420 (133)\ttotal: 2m 6s\tremaining: 5m 46s\n",
            "134:\tlearn: 0.2433925\ttest: 0.2738257\tbest: 0.2738257 (134)\ttotal: 2m 7s\tremaining: 5m 45s\n",
            "135:\tlearn: 0.2418297\ttest: 0.2724066\tbest: 0.2724066 (135)\ttotal: 2m 8s\tremaining: 5m 44s\n",
            "136:\tlearn: 0.2410983\ttest: 0.2718562\tbest: 0.2718562 (136)\ttotal: 2m 10s\tremaining: 5m 45s\n",
            "137:\tlearn: 0.2395498\ttest: 0.2705338\tbest: 0.2705338 (137)\ttotal: 2m 11s\tremaining: 5m 44s\n",
            "138:\tlearn: 0.2387116\ttest: 0.2698553\tbest: 0.2698553 (138)\ttotal: 2m 12s\tremaining: 5m 43s\n",
            "139:\tlearn: 0.2369940\ttest: 0.2683393\tbest: 0.2683393 (139)\ttotal: 2m 12s\tremaining: 5m 41s\n",
            "140:\tlearn: 0.2359197\ttest: 0.2672631\tbest: 0.2672631 (140)\ttotal: 2m 13s\tremaining: 5m 40s\n",
            "141:\tlearn: 0.2351114\ttest: 0.2666416\tbest: 0.2666416 (141)\ttotal: 2m 14s\tremaining: 5m 39s\n",
            "142:\tlearn: 0.2339031\ttest: 0.2656635\tbest: 0.2656635 (142)\ttotal: 2m 15s\tremaining: 5m 37s\n",
            "143:\tlearn: 0.2333467\ttest: 0.2652204\tbest: 0.2652204 (143)\ttotal: 2m 16s\tremaining: 5m 36s\n",
            "144:\tlearn: 0.2318443\ttest: 0.2640410\tbest: 0.2640410 (144)\ttotal: 2m 16s\tremaining: 5m 34s\n",
            "145:\tlearn: 0.2303945\ttest: 0.2627601\tbest: 0.2627601 (145)\ttotal: 2m 17s\tremaining: 5m 33s\n",
            "146:\tlearn: 0.2294208\ttest: 0.2619108\tbest: 0.2619108 (146)\ttotal: 2m 18s\tremaining: 5m 32s\n",
            "147:\tlearn: 0.2281770\ttest: 0.2607818\tbest: 0.2607818 (147)\ttotal: 2m 19s\tremaining: 5m 30s\n",
            "148:\tlearn: 0.2268690\ttest: 0.2596900\tbest: 0.2596900 (148)\ttotal: 2m 19s\tremaining: 5m 29s\n",
            "149:\tlearn: 0.2259994\ttest: 0.2587873\tbest: 0.2587873 (149)\ttotal: 2m 20s\tremaining: 5m 28s\n",
            "150:\tlearn: 0.2252658\ttest: 0.2582351\tbest: 0.2582351 (150)\ttotal: 2m 21s\tremaining: 5m 27s\n",
            "151:\tlearn: 0.2247605\ttest: 0.2577226\tbest: 0.2577226 (151)\ttotal: 2m 23s\tremaining: 5m 28s\n",
            "152:\tlearn: 0.2242950\ttest: 0.2573513\tbest: 0.2573513 (152)\ttotal: 2m 24s\tremaining: 5m 27s\n",
            "153:\tlearn: 0.2234119\ttest: 0.2565751\tbest: 0.2565751 (153)\ttotal: 2m 25s\tremaining: 5m 26s\n",
            "154:\tlearn: 0.2223445\ttest: 0.2556238\tbest: 0.2556238 (154)\ttotal: 2m 25s\tremaining: 5m 24s\n",
            "155:\tlearn: 0.2215219\ttest: 0.2549964\tbest: 0.2549964 (155)\ttotal: 2m 26s\tremaining: 5m 23s\n",
            "156:\tlearn: 0.2202012\ttest: 0.2538829\tbest: 0.2538829 (156)\ttotal: 2m 27s\tremaining: 5m 22s\n",
            "157:\tlearn: 0.2193990\ttest: 0.2532223\tbest: 0.2532223 (157)\ttotal: 2m 28s\tremaining: 5m 20s\n",
            "158:\tlearn: 0.2189724\ttest: 0.2527963\tbest: 0.2527963 (158)\ttotal: 2m 28s\tremaining: 5m 19s\n",
            "159:\tlearn: 0.2183193\ttest: 0.2523401\tbest: 0.2523401 (159)\ttotal: 2m 29s\tremaining: 5m 18s\n",
            "160:\tlearn: 0.2172943\ttest: 0.2513933\tbest: 0.2513933 (160)\ttotal: 2m 30s\tremaining: 5m 16s\n",
            "161:\tlearn: 0.2168591\ttest: 0.2510312\tbest: 0.2510312 (161)\ttotal: 2m 31s\tremaining: 5m 15s\n",
            "162:\tlearn: 0.2158688\ttest: 0.2502589\tbest: 0.2502589 (162)\ttotal: 2m 32s\tremaining: 5m 14s\n",
            "163:\tlearn: 0.2156510\ttest: 0.2500517\tbest: 0.2500517 (163)\ttotal: 2m 32s\tremaining: 5m 13s\n",
            "164:\tlearn: 0.2146296\ttest: 0.2490129\tbest: 0.2490129 (164)\ttotal: 2m 33s\tremaining: 5m 11s\n",
            "165:\tlearn: 0.2138310\ttest: 0.2482811\tbest: 0.2482811 (165)\ttotal: 2m 34s\tremaining: 5m 11s\n",
            "166:\tlearn: 0.2132665\ttest: 0.2478232\tbest: 0.2478232 (166)\ttotal: 2m 36s\tremaining: 5m 11s\n",
            "167:\tlearn: 0.2127754\ttest: 0.2474433\tbest: 0.2474433 (167)\ttotal: 2m 37s\tremaining: 5m 10s\n",
            "168:\tlearn: 0.2118516\ttest: 0.2467283\tbest: 0.2467283 (168)\ttotal: 2m 38s\tremaining: 5m 9s\n",
            "169:\tlearn: 0.2113372\ttest: 0.2463570\tbest: 0.2463570 (169)\ttotal: 2m 38s\tremaining: 5m 8s\n",
            "170:\tlearn: 0.2108926\ttest: 0.2460112\tbest: 0.2460112 (170)\ttotal: 2m 39s\tremaining: 5m 7s\n",
            "171:\tlearn: 0.2099875\ttest: 0.2452749\tbest: 0.2452749 (171)\ttotal: 2m 40s\tremaining: 5m 5s\n",
            "172:\tlearn: 0.2094731\ttest: 0.2448494\tbest: 0.2448494 (172)\ttotal: 2m 41s\tremaining: 5m 4s\n",
            "173:\tlearn: 0.2092755\ttest: 0.2447225\tbest: 0.2447225 (173)\ttotal: 2m 41s\tremaining: 5m 3s\n",
            "174:\tlearn: 0.2086825\ttest: 0.2442533\tbest: 0.2442533 (174)\ttotal: 2m 42s\tremaining: 5m 2s\n",
            "175:\tlearn: 0.2077816\ttest: 0.2434768\tbest: 0.2434768 (175)\ttotal: 2m 43s\tremaining: 5m\n",
            "176:\tlearn: 0.2074271\ttest: 0.2432050\tbest: 0.2432050 (176)\ttotal: 2m 44s\tremaining: 4m 59s\n",
            "177:\tlearn: 0.2071241\ttest: 0.2429465\tbest: 0.2429465 (177)\ttotal: 2m 45s\tremaining: 4m 58s\n",
            "178:\tlearn: 0.2065342\ttest: 0.2423996\tbest: 0.2423996 (178)\ttotal: 2m 45s\tremaining: 4m 57s\n",
            "179:\tlearn: 0.2060088\ttest: 0.2420520\tbest: 0.2420520 (179)\ttotal: 2m 46s\tremaining: 4m 56s\n",
            "180:\tlearn: 0.2054399\ttest: 0.2415846\tbest: 0.2415846 (180)\ttotal: 2m 47s\tremaining: 4m 55s\n",
            "181:\tlearn: 0.2045248\ttest: 0.2407688\tbest: 0.2407688 (181)\ttotal: 2m 49s\tremaining: 4m 56s\n",
            "182:\tlearn: 0.2039871\ttest: 0.2402876\tbest: 0.2402876 (182)\ttotal: 2m 50s\tremaining: 4m 55s\n",
            "183:\tlearn: 0.2030736\ttest: 0.2395001\tbest: 0.2395001 (183)\ttotal: 2m 51s\tremaining: 4m 53s\n",
            "184:\tlearn: 0.2024720\ttest: 0.2389723\tbest: 0.2389723 (184)\ttotal: 2m 51s\tremaining: 4m 52s\n",
            "185:\tlearn: 0.2020639\ttest: 0.2386805\tbest: 0.2386805 (185)\ttotal: 2m 52s\tremaining: 4m 51s\n",
            "186:\tlearn: 0.2016892\ttest: 0.2384071\tbest: 0.2384071 (186)\ttotal: 2m 53s\tremaining: 4m 50s\n",
            "187:\tlearn: 0.2012212\ttest: 0.2379994\tbest: 0.2379994 (187)\ttotal: 2m 54s\tremaining: 4m 49s\n",
            "188:\tlearn: 0.2009136\ttest: 0.2377420\tbest: 0.2377420 (188)\ttotal: 2m 54s\tremaining: 4m 47s\n",
            "189:\tlearn: 0.2005576\ttest: 0.2374271\tbest: 0.2374271 (189)\ttotal: 2m 55s\tremaining: 4m 46s\n",
            "190:\tlearn: 0.1994685\ttest: 0.2364207\tbest: 0.2364207 (190)\ttotal: 2m 56s\tremaining: 4m 45s\n",
            "191:\tlearn: 0.1990544\ttest: 0.2361015\tbest: 0.2361015 (191)\ttotal: 2m 57s\tremaining: 4m 44s\n",
            "192:\tlearn: 0.1983277\ttest: 0.2355285\tbest: 0.2355285 (192)\ttotal: 2m 58s\tremaining: 4m 43s\n",
            "193:\tlearn: 0.1976953\ttest: 0.2350462\tbest: 0.2350462 (193)\ttotal: 2m 58s\tremaining: 4m 42s\n",
            "194:\tlearn: 0.1971537\ttest: 0.2346422\tbest: 0.2346422 (194)\ttotal: 2m 59s\tremaining: 4m 40s\n",
            "195:\tlearn: 0.1968760\ttest: 0.2343831\tbest: 0.2343831 (195)\ttotal: 3m\tremaining: 4m 40s\n",
            "196:\tlearn: 0.1965212\ttest: 0.2341617\tbest: 0.2341617 (196)\ttotal: 3m 2s\tremaining: 4m 40s\n",
            "197:\tlearn: 0.1958027\ttest: 0.2334797\tbest: 0.2334797 (197)\ttotal: 3m 3s\tremaining: 4m 39s\n",
            "198:\tlearn: 0.1954513\ttest: 0.2333120\tbest: 0.2333120 (198)\ttotal: 3m 4s\tremaining: 4m 38s\n",
            "199:\tlearn: 0.1948990\ttest: 0.2327871\tbest: 0.2327871 (199)\ttotal: 3m 4s\tremaining: 4m 37s\n",
            "200:\tlearn: 0.1945090\ttest: 0.2324610\tbest: 0.2324610 (200)\ttotal: 3m 5s\tremaining: 4m 36s\n",
            "201:\tlearn: 0.1940322\ttest: 0.2321298\tbest: 0.2321298 (201)\ttotal: 3m 6s\tremaining: 4m 34s\n",
            "202:\tlearn: 0.1937884\ttest: 0.2319407\tbest: 0.2319407 (202)\ttotal: 3m 7s\tremaining: 4m 33s\n",
            "203:\tlearn: 0.1934392\ttest: 0.2316844\tbest: 0.2316844 (203)\ttotal: 3m 7s\tremaining: 4m 32s\n",
            "204:\tlearn: 0.1928989\ttest: 0.2311596\tbest: 0.2311596 (204)\ttotal: 3m 8s\tremaining: 4m 31s\n",
            "205:\tlearn: 0.1920944\ttest: 0.2304785\tbest: 0.2304785 (205)\ttotal: 3m 9s\tremaining: 4m 30s\n",
            "206:\tlearn: 0.1917221\ttest: 0.2301722\tbest: 0.2301722 (206)\ttotal: 3m 10s\tremaining: 4m 29s\n",
            "207:\tlearn: 0.1913792\ttest: 0.2298745\tbest: 0.2298745 (207)\ttotal: 3m 10s\tremaining: 4m 28s\n",
            "208:\tlearn: 0.1911209\ttest: 0.2297023\tbest: 0.2297023 (208)\ttotal: 3m 11s\tremaining: 4m 26s\n",
            "209:\tlearn: 0.1905945\ttest: 0.2293062\tbest: 0.2293062 (209)\ttotal: 3m 12s\tremaining: 4m 25s\n",
            "210:\tlearn: 0.1902101\ttest: 0.2290039\tbest: 0.2290039 (210)\ttotal: 3m 13s\tremaining: 4m 25s\n",
            "211:\tlearn: 0.1899165\ttest: 0.2287719\tbest: 0.2287719 (211)\ttotal: 3m 15s\tremaining: 4m 25s\n",
            "212:\tlearn: 0.1896067\ttest: 0.2286007\tbest: 0.2286007 (212)\ttotal: 3m 16s\tremaining: 4m 24s\n",
            "213:\tlearn: 0.1894156\ttest: 0.2283995\tbest: 0.2283995 (213)\ttotal: 3m 16s\tremaining: 4m 23s\n",
            "214:\tlearn: 0.1884905\ttest: 0.2275771\tbest: 0.2275771 (214)\ttotal: 3m 17s\tremaining: 4m 21s\n",
            "215:\tlearn: 0.1879887\ttest: 0.2271784\tbest: 0.2271784 (215)\ttotal: 3m 18s\tremaining: 4m 20s\n",
            "216:\tlearn: 0.1867102\ttest: 0.2259830\tbest: 0.2259830 (216)\ttotal: 3m 19s\tremaining: 4m 19s\n",
            "217:\tlearn: 0.1862190\ttest: 0.2255568\tbest: 0.2255568 (217)\ttotal: 3m 19s\tremaining: 4m 18s\n",
            "218:\tlearn: 0.1859768\ttest: 0.2254025\tbest: 0.2254025 (218)\ttotal: 3m 20s\tremaining: 4m 17s\n",
            "219:\tlearn: 0.1856762\ttest: 0.2252011\tbest: 0.2252011 (219)\ttotal: 3m 21s\tremaining: 4m 16s\n",
            "220:\tlearn: 0.1853383\ttest: 0.2248854\tbest: 0.2248854 (220)\ttotal: 3m 22s\tremaining: 4m 15s\n",
            "221:\tlearn: 0.1850257\ttest: 0.2246400\tbest: 0.2246400 (221)\ttotal: 3m 23s\tremaining: 4m 14s\n",
            "222:\tlearn: 0.1844533\ttest: 0.2241969\tbest: 0.2241969 (222)\ttotal: 3m 23s\tremaining: 4m 13s\n",
            "223:\tlearn: 0.1841355\ttest: 0.2239888\tbest: 0.2239888 (223)\ttotal: 3m 24s\tremaining: 4m 12s\n",
            "224:\tlearn: 0.1838131\ttest: 0.2237322\tbest: 0.2237322 (224)\ttotal: 3m 25s\tremaining: 4m 10s\n",
            "225:\tlearn: 0.1834153\ttest: 0.2233371\tbest: 0.2233371 (225)\ttotal: 3m 26s\tremaining: 4m 10s\n",
            "226:\tlearn: 0.1830380\ttest: 0.2229806\tbest: 0.2229806 (226)\ttotal: 3m 28s\tremaining: 4m 10s\n",
            "227:\tlearn: 0.1823007\ttest: 0.2223541\tbest: 0.2223541 (227)\ttotal: 3m 28s\tremaining: 4m 9s\n",
            "228:\tlearn: 0.1819736\ttest: 0.2220190\tbest: 0.2220190 (228)\ttotal: 3m 29s\tremaining: 4m 8s\n",
            "229:\tlearn: 0.1815692\ttest: 0.2216745\tbest: 0.2216745 (229)\ttotal: 3m 30s\tremaining: 4m 7s\n",
            "230:\tlearn: 0.1807878\ttest: 0.2209704\tbest: 0.2209704 (230)\ttotal: 3m 31s\tremaining: 4m 6s\n",
            "231:\tlearn: 0.1805663\ttest: 0.2208419\tbest: 0.2208419 (231)\ttotal: 3m 32s\tremaining: 4m 4s\n",
            "232:\tlearn: 0.1804309\ttest: 0.2207475\tbest: 0.2207475 (232)\ttotal: 3m 32s\tremaining: 4m 3s\n",
            "233:\tlearn: 0.1801526\ttest: 0.2205382\tbest: 0.2205382 (233)\ttotal: 3m 33s\tremaining: 4m 2s\n",
            "234:\tlearn: 0.1798408\ttest: 0.2203349\tbest: 0.2203349 (234)\ttotal: 3m 34s\tremaining: 4m 1s\n",
            "235:\tlearn: 0.1796640\ttest: 0.2201891\tbest: 0.2201891 (235)\ttotal: 3m 35s\tremaining: 4m\n",
            "236:\tlearn: 0.1794616\ttest: 0.2200904\tbest: 0.2200904 (236)\ttotal: 3m 35s\tremaining: 3m 59s\n",
            "237:\tlearn: 0.1791053\ttest: 0.2198072\tbest: 0.2198072 (237)\ttotal: 3m 36s\tremaining: 3m 58s\n",
            "238:\tlearn: 0.1786817\ttest: 0.2194198\tbest: 0.2194198 (238)\ttotal: 3m 37s\tremaining: 3m 57s\n",
            "239:\tlearn: 0.1783983\ttest: 0.2192665\tbest: 0.2192665 (239)\ttotal: 3m 38s\tremaining: 3m 56s\n",
            "240:\tlearn: 0.1778304\ttest: 0.2187357\tbest: 0.2187357 (240)\ttotal: 3m 39s\tremaining: 3m 55s\n",
            "241:\tlearn: 0.1771748\ttest: 0.2181169\tbest: 0.2181169 (241)\ttotal: 3m 40s\tremaining: 3m 55s\n",
            "242:\tlearn: 0.1769739\ttest: 0.2179346\tbest: 0.2179346 (242)\ttotal: 3m 41s\tremaining: 3m 54s\n",
            "243:\tlearn: 0.1768046\ttest: 0.2177977\tbest: 0.2177977 (243)\ttotal: 3m 42s\tremaining: 3m 53s\n",
            "244:\tlearn: 0.1759418\ttest: 0.2171268\tbest: 0.2171268 (244)\ttotal: 3m 43s\tremaining: 3m 52s\n",
            "245:\tlearn: 0.1754180\ttest: 0.2166836\tbest: 0.2166836 (245)\ttotal: 3m 44s\tremaining: 3m 51s\n",
            "246:\tlearn: 0.1750387\ttest: 0.2164583\tbest: 0.2164583 (246)\ttotal: 3m 44s\tremaining: 3m 50s\n",
            "247:\tlearn: 0.1744783\ttest: 0.2160528\tbest: 0.2160528 (247)\ttotal: 3m 45s\tremaining: 3m 49s\n",
            "248:\tlearn: 0.1742101\ttest: 0.2157927\tbest: 0.2157927 (248)\ttotal: 3m 46s\tremaining: 3m 48s\n",
            "249:\tlearn: 0.1737549\ttest: 0.2154123\tbest: 0.2154123 (249)\ttotal: 3m 47s\tremaining: 3m 47s\n",
            "250:\tlearn: 0.1734864\ttest: 0.2152226\tbest: 0.2152226 (250)\ttotal: 3m 47s\tremaining: 3m 46s\n",
            "251:\tlearn: 0.1732726\ttest: 0.2150809\tbest: 0.2150809 (251)\ttotal: 3m 48s\tremaining: 3m 45s\n",
            "252:\tlearn: 0.1728637\ttest: 0.2147509\tbest: 0.2147509 (252)\ttotal: 3m 49s\tremaining: 3m 44s\n",
            "253:\tlearn: 0.1725444\ttest: 0.2145222\tbest: 0.2145222 (253)\ttotal: 3m 50s\tremaining: 3m 43s\n",
            "254:\tlearn: 0.1722901\ttest: 0.2143560\tbest: 0.2143560 (254)\ttotal: 3m 51s\tremaining: 3m 41s\n",
            "255:\tlearn: 0.1721093\ttest: 0.2142475\tbest: 0.2142475 (255)\ttotal: 3m 51s\tremaining: 3m 41s\n",
            "256:\tlearn: 0.1719165\ttest: 0.2141195\tbest: 0.2141195 (256)\ttotal: 3m 53s\tremaining: 3m 40s\n",
            "257:\tlearn: 0.1712008\ttest: 0.2134628\tbest: 0.2134628 (257)\ttotal: 3m 54s\tremaining: 3m 40s\n",
            "258:\tlearn: 0.1711212\ttest: 0.2134121\tbest: 0.2134121 (258)\ttotal: 3m 55s\tremaining: 3m 39s\n",
            "259:\tlearn: 0.1707091\ttest: 0.2131119\tbest: 0.2131119 (259)\ttotal: 3m 56s\tremaining: 3m 38s\n",
            "260:\tlearn: 0.1703765\ttest: 0.2128486\tbest: 0.2128486 (260)\ttotal: 3m 56s\tremaining: 3m 37s\n",
            "261:\tlearn: 0.1701112\ttest: 0.2126778\tbest: 0.2126778 (261)\ttotal: 3m 57s\tremaining: 3m 35s\n",
            "262:\tlearn: 0.1698967\ttest: 0.2124943\tbest: 0.2124943 (262)\ttotal: 3m 58s\tremaining: 3m 34s\n",
            "263:\tlearn: 0.1696308\ttest: 0.2123046\tbest: 0.2123046 (263)\ttotal: 3m 59s\tremaining: 3m 33s\n",
            "264:\tlearn: 0.1690833\ttest: 0.2118164\tbest: 0.2118164 (264)\ttotal: 4m\tremaining: 3m 32s\n",
            "265:\tlearn: 0.1687402\ttest: 0.2115586\tbest: 0.2115586 (265)\ttotal: 4m\tremaining: 3m 31s\n",
            "266:\tlearn: 0.1683764\ttest: 0.2113537\tbest: 0.2113537 (266)\ttotal: 4m 1s\tremaining: 3m 30s\n",
            "267:\tlearn: 0.1679475\ttest: 0.2110613\tbest: 0.2110613 (267)\ttotal: 4m 2s\tremaining: 3m 29s\n",
            "268:\tlearn: 0.1675974\ttest: 0.2107807\tbest: 0.2107807 (268)\ttotal: 4m 3s\tremaining: 3m 28s\n",
            "269:\tlearn: 0.1674255\ttest: 0.2106457\tbest: 0.2106457 (269)\ttotal: 4m 3s\tremaining: 3m 27s\n",
            "270:\tlearn: 0.1672240\ttest: 0.2105242\tbest: 0.2105242 (270)\ttotal: 4m 4s\tremaining: 3m 26s\n",
            "271:\tlearn: 0.1670783\ttest: 0.2103874\tbest: 0.2103874 (271)\ttotal: 4m 6s\tremaining: 3m 26s\n",
            "272:\tlearn: 0.1668700\ttest: 0.2102521\tbest: 0.2102521 (272)\ttotal: 4m 7s\tremaining: 3m 25s\n",
            "273:\tlearn: 0.1665927\ttest: 0.2100181\tbest: 0.2100181 (273)\ttotal: 4m 8s\tremaining: 3m 24s\n",
            "274:\tlearn: 0.1664268\ttest: 0.2098787\tbest: 0.2098787 (274)\ttotal: 4m 9s\tremaining: 3m 23s\n",
            "275:\tlearn: 0.1661437\ttest: 0.2096545\tbest: 0.2096545 (275)\ttotal: 4m 9s\tremaining: 3m 22s\n",
            "276:\tlearn: 0.1659910\ttest: 0.2094994\tbest: 0.2094994 (276)\ttotal: 4m 10s\tremaining: 3m 21s\n",
            "277:\tlearn: 0.1657948\ttest: 0.2093788\tbest: 0.2093788 (277)\ttotal: 4m 11s\tremaining: 3m 20s\n",
            "278:\tlearn: 0.1652483\ttest: 0.2088733\tbest: 0.2088733 (278)\ttotal: 4m 12s\tremaining: 3m 19s\n",
            "279:\tlearn: 0.1650184\ttest: 0.2087016\tbest: 0.2087016 (279)\ttotal: 4m 12s\tremaining: 3m 18s\n",
            "280:\tlearn: 0.1647559\ttest: 0.2085552\tbest: 0.2085552 (280)\ttotal: 4m 13s\tremaining: 3m 17s\n",
            "281:\tlearn: 0.1644846\ttest: 0.2083730\tbest: 0.2083730 (281)\ttotal: 4m 14s\tremaining: 3m 16s\n",
            "282:\tlearn: 0.1643953\ttest: 0.2083187\tbest: 0.2083187 (282)\ttotal: 4m 15s\tremaining: 3m 15s\n",
            "283:\tlearn: 0.1642332\ttest: 0.2081879\tbest: 0.2081879 (283)\ttotal: 4m 15s\tremaining: 3m 14s\n",
            "284:\tlearn: 0.1640152\ttest: 0.2080465\tbest: 0.2080465 (284)\ttotal: 4m 16s\tremaining: 3m 13s\n",
            "285:\tlearn: 0.1637915\ttest: 0.2079076\tbest: 0.2079076 (285)\ttotal: 4m 17s\tremaining: 3m 12s\n",
            "286:\tlearn: 0.1636387\ttest: 0.2077920\tbest: 0.2077920 (286)\ttotal: 4m 18s\tremaining: 3m 11s\n",
            "287:\tlearn: 0.1634533\ttest: 0.2076311\tbest: 0.2076311 (287)\ttotal: 4m 20s\tremaining: 3m 11s\n",
            "288:\tlearn: 0.1633235\ttest: 0.2075598\tbest: 0.2075598 (288)\ttotal: 4m 21s\tremaining: 3m 10s\n",
            "289:\tlearn: 0.1629753\ttest: 0.2072483\tbest: 0.2072483 (289)\ttotal: 4m 22s\tremaining: 3m 10s\n",
            "290:\tlearn: 0.1625524\ttest: 0.2069667\tbest: 0.2069667 (290)\ttotal: 4m 23s\tremaining: 3m 9s\n",
            "291:\tlearn: 0.1624148\ttest: 0.2068491\tbest: 0.2068491 (291)\ttotal: 4m 24s\tremaining: 3m 8s\n",
            "292:\tlearn: 0.1622167\ttest: 0.2067127\tbest: 0.2067127 (292)\ttotal: 4m 25s\tremaining: 3m 7s\n",
            "293:\tlearn: 0.1618877\ttest: 0.2064771\tbest: 0.2064771 (293)\ttotal: 4m 26s\tremaining: 3m 6s\n",
            "294:\tlearn: 0.1617830\ttest: 0.2064019\tbest: 0.2064019 (294)\ttotal: 4m 27s\tremaining: 3m 5s\n",
            "295:\tlearn: 0.1616316\ttest: 0.2062703\tbest: 0.2062703 (295)\ttotal: 4m 27s\tremaining: 3m 4s\n",
            "296:\tlearn: 0.1614816\ttest: 0.2061418\tbest: 0.2061418 (296)\ttotal: 4m 28s\tremaining: 3m 3s\n",
            "297:\tlearn: 0.1612863\ttest: 0.2059715\tbest: 0.2059715 (297)\ttotal: 4m 29s\tremaining: 3m 2s\n",
            "298:\tlearn: 0.1608656\ttest: 0.2055691\tbest: 0.2055691 (298)\ttotal: 4m 30s\tremaining: 3m 1s\n",
            "299:\tlearn: 0.1607100\ttest: 0.2054666\tbest: 0.2054666 (299)\ttotal: 4m 31s\tremaining: 3m\n",
            "300:\tlearn: 0.1605519\ttest: 0.2053394\tbest: 0.2053394 (300)\ttotal: 4m 32s\tremaining: 3m\n",
            "301:\tlearn: 0.1603472\ttest: 0.2051886\tbest: 0.2051886 (301)\ttotal: 4m 33s\tremaining: 2m 59s\n",
            "302:\tlearn: 0.1600860\ttest: 0.2049628\tbest: 0.2049628 (302)\ttotal: 4m 34s\tremaining: 2m 58s\n",
            "303:\tlearn: 0.1598484\ttest: 0.2047905\tbest: 0.2047905 (303)\ttotal: 4m 35s\tremaining: 2m 57s\n",
            "304:\tlearn: 0.1596525\ttest: 0.2046855\tbest: 0.2046855 (304)\ttotal: 4m 36s\tremaining: 2m 56s\n",
            "305:\tlearn: 0.1593335\ttest: 0.2044174\tbest: 0.2044174 (305)\ttotal: 4m 36s\tremaining: 2m 55s\n",
            "306:\tlearn: 0.1592522\ttest: 0.2043450\tbest: 0.2043450 (306)\ttotal: 4m 37s\tremaining: 2m 54s\n",
            "307:\tlearn: 0.1591427\ttest: 0.2042801\tbest: 0.2042801 (307)\ttotal: 4m 38s\tremaining: 2m 53s\n",
            "308:\tlearn: 0.1589157\ttest: 0.2040585\tbest: 0.2040585 (308)\ttotal: 4m 39s\tremaining: 2m 52s\n",
            "309:\tlearn: 0.1585770\ttest: 0.2038115\tbest: 0.2038115 (309)\ttotal: 4m 39s\tremaining: 2m 51s\n",
            "310:\tlearn: 0.1582196\ttest: 0.2035822\tbest: 0.2035822 (310)\ttotal: 4m 40s\tremaining: 2m 50s\n",
            "311:\tlearn: 0.1579948\ttest: 0.2033470\tbest: 0.2033470 (311)\ttotal: 4m 41s\tremaining: 2m 49s\n",
            "312:\tlearn: 0.1575262\ttest: 0.2029218\tbest: 0.2029218 (312)\ttotal: 4m 42s\tremaining: 2m 48s\n",
            "313:\tlearn: 0.1572601\ttest: 0.2026926\tbest: 0.2026926 (313)\ttotal: 4m 42s\tremaining: 2m 47s\n",
            "314:\tlearn: 0.1570140\ttest: 0.2025519\tbest: 0.2025519 (314)\ttotal: 4m 43s\tremaining: 2m 46s\n",
            "315:\tlearn: 0.1569278\ttest: 0.2024870\tbest: 0.2024870 (315)\ttotal: 4m 45s\tremaining: 2m 46s\n",
            "316:\tlearn: 0.1567449\ttest: 0.2023311\tbest: 0.2023311 (316)\ttotal: 4m 46s\tremaining: 2m 45s\n",
            "317:\tlearn: 0.1565824\ttest: 0.2022309\tbest: 0.2022309 (317)\ttotal: 4m 47s\tremaining: 2m 44s\n",
            "318:\tlearn: 0.1564358\ttest: 0.2021024\tbest: 0.2021024 (318)\ttotal: 4m 48s\tremaining: 2m 43s\n",
            "319:\tlearn: 0.1563139\ttest: 0.2019875\tbest: 0.2019875 (319)\ttotal: 4m 48s\tremaining: 2m 42s\n",
            "320:\tlearn: 0.1562004\ttest: 0.2018852\tbest: 0.2018852 (320)\ttotal: 4m 49s\tremaining: 2m 41s\n",
            "321:\tlearn: 0.1560661\ttest: 0.2018077\tbest: 0.2018077 (321)\ttotal: 4m 50s\tremaining: 2m 40s\n",
            "322:\tlearn: 0.1559462\ttest: 0.2017055\tbest: 0.2017055 (322)\ttotal: 4m 51s\tremaining: 2m 39s\n",
            "323:\tlearn: 0.1557835\ttest: 0.2015846\tbest: 0.2015846 (323)\ttotal: 4m 51s\tremaining: 2m 38s\n",
            "324:\tlearn: 0.1555913\ttest: 0.2014439\tbest: 0.2014439 (324)\ttotal: 4m 52s\tremaining: 2m 37s\n",
            "325:\tlearn: 0.1554511\ttest: 0.2013541\tbest: 0.2013541 (325)\ttotal: 4m 53s\tremaining: 2m 36s\n",
            "326:\tlearn: 0.1552634\ttest: 0.2012155\tbest: 0.2012155 (326)\ttotal: 4m 54s\tremaining: 2m 35s\n",
            "327:\tlearn: 0.1550396\ttest: 0.2010717\tbest: 0.2010717 (327)\ttotal: 4m 54s\tremaining: 2m 34s\n",
            "328:\tlearn: 0.1549436\ttest: 0.2010032\tbest: 0.2010032 (328)\ttotal: 4m 55s\tremaining: 2m 33s\n",
            "329:\tlearn: 0.1547935\ttest: 0.2009083\tbest: 0.2009083 (329)\ttotal: 4m 56s\tremaining: 2m 32s\n",
            "330:\tlearn: 0.1543857\ttest: 0.2005808\tbest: 0.2005808 (330)\ttotal: 4m 57s\tremaining: 2m 32s\n",
            "331:\tlearn: 0.1542338\ttest: 0.2004516\tbest: 0.2004516 (331)\ttotal: 4m 59s\tremaining: 2m 31s\n",
            "332:\tlearn: 0.1540575\ttest: 0.2003321\tbest: 0.2003321 (332)\ttotal: 5m\tremaining: 2m 30s\n",
            "333:\tlearn: 0.1538360\ttest: 0.2001730\tbest: 0.2001730 (333)\ttotal: 5m\tremaining: 2m 29s\n",
            "334:\tlearn: 0.1536849\ttest: 0.2000527\tbest: 0.2000527 (334)\ttotal: 5m 1s\tremaining: 2m 28s\n",
            "335:\tlearn: 0.1535528\ttest: 0.1999499\tbest: 0.1999499 (335)\ttotal: 5m 2s\tremaining: 2m 27s\n",
            "336:\tlearn: 0.1534241\ttest: 0.1998861\tbest: 0.1998861 (336)\ttotal: 5m 3s\tremaining: 2m 26s\n",
            "337:\tlearn: 0.1533005\ttest: 0.1998095\tbest: 0.1998095 (337)\ttotal: 5m 3s\tremaining: 2m 25s\n",
            "338:\tlearn: 0.1531313\ttest: 0.1996817\tbest: 0.1996817 (338)\ttotal: 5m 4s\tremaining: 2m 24s\n",
            "339:\tlearn: 0.1530713\ttest: 0.1996285\tbest: 0.1996285 (339)\ttotal: 5m 5s\tremaining: 2m 23s\n",
            "340:\tlearn: 0.1529182\ttest: 0.1994592\tbest: 0.1994592 (340)\ttotal: 5m 6s\tremaining: 2m 22s\n",
            "341:\tlearn: 0.1527482\ttest: 0.1993383\tbest: 0.1993383 (341)\ttotal: 5m 7s\tremaining: 2m 21s\n",
            "342:\tlearn: 0.1524966\ttest: 0.1991771\tbest: 0.1991771 (342)\ttotal: 5m 7s\tremaining: 2m 20s\n",
            "343:\tlearn: 0.1523461\ttest: 0.1990515\tbest: 0.1990515 (343)\ttotal: 5m 8s\tremaining: 2m 19s\n",
            "344:\tlearn: 0.1521274\ttest: 0.1988295\tbest: 0.1988295 (344)\ttotal: 5m 9s\tremaining: 2m 18s\n",
            "345:\tlearn: 0.1519394\ttest: 0.1986854\tbest: 0.1986854 (345)\ttotal: 5m 10s\tremaining: 2m 18s\n",
            "346:\tlearn: 0.1517212\ttest: 0.1984812\tbest: 0.1984812 (346)\ttotal: 5m 11s\tremaining: 2m 17s\n",
            "347:\tlearn: 0.1515977\ttest: 0.1983597\tbest: 0.1983597 (347)\ttotal: 5m 12s\tremaining: 2m 16s\n",
            "348:\tlearn: 0.1514368\ttest: 0.1982375\tbest: 0.1982375 (348)\ttotal: 5m 13s\tremaining: 2m 15s\n",
            "349:\tlearn: 0.1512243\ttest: 0.1981200\tbest: 0.1981200 (349)\ttotal: 5m 14s\tremaining: 2m 14s\n",
            "350:\tlearn: 0.1511050\ttest: 0.1980442\tbest: 0.1980442 (350)\ttotal: 5m 15s\tremaining: 2m 13s\n",
            "351:\tlearn: 0.1508755\ttest: 0.1979180\tbest: 0.1979180 (351)\ttotal: 5m 15s\tremaining: 2m 12s\n",
            "352:\tlearn: 0.1507335\ttest: 0.1978134\tbest: 0.1978134 (352)\ttotal: 5m 16s\tremaining: 2m 11s\n",
            "353:\tlearn: 0.1506108\ttest: 0.1977101\tbest: 0.1977101 (353)\ttotal: 5m 17s\tremaining: 2m 10s\n",
            "354:\tlearn: 0.1504573\ttest: 0.1975737\tbest: 0.1975737 (354)\ttotal: 5m 18s\tremaining: 2m 9s\n",
            "355:\tlearn: 0.1501381\ttest: 0.1973448\tbest: 0.1973448 (355)\ttotal: 5m 19s\tremaining: 2m 9s\n",
            "356:\tlearn: 0.1499798\ttest: 0.1971945\tbest: 0.1971945 (356)\ttotal: 5m 19s\tremaining: 2m 8s\n",
            "357:\tlearn: 0.1498432\ttest: 0.1970802\tbest: 0.1970802 (357)\ttotal: 5m 20s\tremaining: 2m 7s\n",
            "358:\tlearn: 0.1495982\ttest: 0.1968432\tbest: 0.1968432 (358)\ttotal: 5m 21s\tremaining: 2m 6s\n",
            "359:\tlearn: 0.1493728\ttest: 0.1966841\tbest: 0.1966841 (359)\ttotal: 5m 22s\tremaining: 2m 5s\n",
            "360:\tlearn: 0.1493020\ttest: 0.1966389\tbest: 0.1966389 (360)\ttotal: 5m 23s\tremaining: 2m 4s\n",
            "361:\tlearn: 0.1491457\ttest: 0.1965319\tbest: 0.1965319 (361)\ttotal: 5m 24s\tremaining: 2m 3s\n",
            "362:\tlearn: 0.1488607\ttest: 0.1963265\tbest: 0.1963265 (362)\ttotal: 5m 25s\tremaining: 2m 2s\n",
            "363:\tlearn: 0.1487225\ttest: 0.1962237\tbest: 0.1962237 (363)\ttotal: 5m 26s\tremaining: 2m 1s\n",
            "364:\tlearn: 0.1485800\ttest: 0.1961430\tbest: 0.1961430 (364)\ttotal: 5m 27s\tremaining: 2m 1s\n",
            "365:\tlearn: 0.1485040\ttest: 0.1961073\tbest: 0.1961073 (365)\ttotal: 5m 28s\tremaining: 2m\n",
            "366:\tlearn: 0.1483034\ttest: 0.1959437\tbest: 0.1959437 (366)\ttotal: 5m 28s\tremaining: 1m 59s\n",
            "367:\tlearn: 0.1481450\ttest: 0.1958714\tbest: 0.1958714 (367)\ttotal: 5m 29s\tremaining: 1m 58s\n",
            "368:\tlearn: 0.1480531\ttest: 0.1957772\tbest: 0.1957772 (368)\ttotal: 5m 30s\tremaining: 1m 57s\n",
            "369:\tlearn: 0.1477698\ttest: 0.1954450\tbest: 0.1954450 (369)\ttotal: 5m 31s\tremaining: 1m 56s\n",
            "370:\tlearn: 0.1469736\ttest: 0.1948210\tbest: 0.1948210 (370)\ttotal: 5m 31s\tremaining: 1m 55s\n",
            "371:\tlearn: 0.1467639\ttest: 0.1946805\tbest: 0.1946805 (371)\ttotal: 5m 32s\tremaining: 1m 54s\n",
            "372:\tlearn: 0.1466406\ttest: 0.1946257\tbest: 0.1946257 (372)\ttotal: 5m 33s\tremaining: 1m 53s\n",
            "373:\tlearn: 0.1464380\ttest: 0.1944938\tbest: 0.1944938 (373)\ttotal: 5m 34s\tremaining: 1m 52s\n",
            "374:\tlearn: 0.1462941\ttest: 0.1943889\tbest: 0.1943889 (374)\ttotal: 5m 34s\tremaining: 1m 51s\n",
            "375:\tlearn: 0.1461893\ttest: 0.1943102\tbest: 0.1943102 (375)\ttotal: 5m 35s\tremaining: 1m 50s\n",
            "376:\tlearn: 0.1459521\ttest: 0.1941269\tbest: 0.1941269 (376)\ttotal: 5m 37s\tremaining: 1m 50s\n",
            "377:\tlearn: 0.1459014\ttest: 0.1941112\tbest: 0.1941112 (377)\ttotal: 5m 38s\tremaining: 1m 49s\n",
            "378:\tlearn: 0.1457249\ttest: 0.1939989\tbest: 0.1939989 (378)\ttotal: 5m 39s\tremaining: 1m 48s\n",
            "379:\tlearn: 0.1455416\ttest: 0.1938326\tbest: 0.1938326 (379)\ttotal: 5m 40s\tremaining: 1m 47s\n",
            "380:\tlearn: 0.1453717\ttest: 0.1936693\tbest: 0.1936693 (380)\ttotal: 5m 40s\tremaining: 1m 46s\n",
            "381:\tlearn: 0.1452577\ttest: 0.1936204\tbest: 0.1936204 (381)\ttotal: 5m 41s\tremaining: 1m 45s\n",
            "382:\tlearn: 0.1447142\ttest: 0.1931295\tbest: 0.1931295 (382)\ttotal: 5m 42s\tremaining: 1m 44s\n",
            "383:\tlearn: 0.1445434\ttest: 0.1929862\tbest: 0.1929862 (383)\ttotal: 5m 43s\tremaining: 1m 43s\n",
            "384:\tlearn: 0.1443406\ttest: 0.1928964\tbest: 0.1928964 (384)\ttotal: 5m 43s\tremaining: 1m 42s\n",
            "385:\tlearn: 0.1442646\ttest: 0.1928228\tbest: 0.1928228 (385)\ttotal: 5m 44s\tremaining: 1m 41s\n",
            "386:\tlearn: 0.1441869\ttest: 0.1927668\tbest: 0.1927668 (386)\ttotal: 5m 45s\tremaining: 1m 40s\n",
            "387:\tlearn: 0.1439208\ttest: 0.1925815\tbest: 0.1925815 (387)\ttotal: 5m 46s\tremaining: 1m 39s\n",
            "388:\tlearn: 0.1436930\ttest: 0.1924171\tbest: 0.1924171 (388)\ttotal: 5m 47s\tremaining: 1m 39s\n",
            "389:\tlearn: 0.1435571\ttest: 0.1923121\tbest: 0.1923121 (389)\ttotal: 5m 47s\tremaining: 1m 38s\n",
            "390:\tlearn: 0.1434123\ttest: 0.1921669\tbest: 0.1921669 (390)\ttotal: 5m 48s\tremaining: 1m 37s\n",
            "391:\tlearn: 0.1431451\ttest: 0.1919071\tbest: 0.1919071 (391)\ttotal: 5m 49s\tremaining: 1m 36s\n",
            "392:\tlearn: 0.1430367\ttest: 0.1918372\tbest: 0.1918372 (392)\ttotal: 5m 51s\tremaining: 1m 35s\n",
            "393:\tlearn: 0.1429192\ttest: 0.1917515\tbest: 0.1917515 (393)\ttotal: 5m 52s\tremaining: 1m 34s\n",
            "394:\tlearn: 0.1428110\ttest: 0.1916874\tbest: 0.1916874 (394)\ttotal: 5m 52s\tremaining: 1m 33s\n",
            "395:\tlearn: 0.1426846\ttest: 0.1915630\tbest: 0.1915630 (395)\ttotal: 5m 53s\tremaining: 1m 32s\n",
            "396:\tlearn: 0.1425137\ttest: 0.1914935\tbest: 0.1914935 (396)\ttotal: 5m 54s\tremaining: 1m 31s\n",
            "397:\tlearn: 0.1423370\ttest: 0.1914033\tbest: 0.1914033 (397)\ttotal: 5m 55s\tremaining: 1m 31s\n",
            "398:\tlearn: 0.1421684\ttest: 0.1913267\tbest: 0.1913267 (398)\ttotal: 5m 56s\tremaining: 1m 30s\n",
            "399:\tlearn: 0.1417582\ttest: 0.1909085\tbest: 0.1909085 (399)\ttotal: 5m 56s\tremaining: 1m 29s\n",
            "400:\tlearn: 0.1415019\ttest: 0.1907628\tbest: 0.1907628 (400)\ttotal: 5m 57s\tremaining: 1m 28s\n",
            "401:\tlearn: 0.1413990\ttest: 0.1907065\tbest: 0.1907065 (401)\ttotal: 5m 58s\tremaining: 1m 27s\n",
            "402:\tlearn: 0.1411984\ttest: 0.1905865\tbest: 0.1905865 (402)\ttotal: 5m 59s\tremaining: 1m 26s\n",
            "403:\tlearn: 0.1410410\ttest: 0.1904778\tbest: 0.1904778 (403)\ttotal: 5m 59s\tremaining: 1m 25s\n",
            "404:\tlearn: 0.1409228\ttest: 0.1904404\tbest: 0.1904404 (404)\ttotal: 6m\tremaining: 1m 24s\n",
            "405:\tlearn: 0.1407601\ttest: 0.1903412\tbest: 0.1903412 (405)\ttotal: 6m 1s\tremaining: 1m 23s\n",
            "406:\tlearn: 0.1406602\ttest: 0.1902824\tbest: 0.1902824 (406)\ttotal: 6m 2s\tremaining: 1m 22s\n",
            "407:\tlearn: 0.1405302\ttest: 0.1901966\tbest: 0.1901966 (407)\ttotal: 6m 4s\tremaining: 1m 22s\n",
            "408:\tlearn: 0.1403706\ttest: 0.1901090\tbest: 0.1901090 (408)\ttotal: 6m 5s\tremaining: 1m 21s\n",
            "409:\tlearn: 0.1402655\ttest: 0.1900773\tbest: 0.1900773 (409)\ttotal: 6m 5s\tremaining: 1m 20s\n",
            "410:\tlearn: 0.1401314\ttest: 0.1900067\tbest: 0.1900067 (410)\ttotal: 6m 6s\tremaining: 1m 19s\n",
            "411:\tlearn: 0.1400463\ttest: 0.1899846\tbest: 0.1899846 (411)\ttotal: 6m 7s\tremaining: 1m 18s\n",
            "412:\tlearn: 0.1397497\ttest: 0.1897812\tbest: 0.1897812 (412)\ttotal: 6m 8s\tremaining: 1m 17s\n",
            "413:\tlearn: 0.1396663\ttest: 0.1897400\tbest: 0.1897400 (413)\ttotal: 6m 8s\tremaining: 1m 16s\n",
            "414:\tlearn: 0.1394520\ttest: 0.1895396\tbest: 0.1895396 (414)\ttotal: 6m 9s\tremaining: 1m 15s\n",
            "415:\tlearn: 0.1393583\ttest: 0.1894845\tbest: 0.1894845 (415)\ttotal: 6m 10s\tremaining: 1m 14s\n",
            "416:\tlearn: 0.1392283\ttest: 0.1894119\tbest: 0.1894119 (416)\ttotal: 6m 11s\tremaining: 1m 13s\n",
            "417:\tlearn: 0.1390038\ttest: 0.1892612\tbest: 0.1892612 (417)\ttotal: 6m 11s\tremaining: 1m 12s\n",
            "418:\tlearn: 0.1387925\ttest: 0.1891223\tbest: 0.1891223 (418)\ttotal: 6m 12s\tremaining: 1m 12s\n",
            "419:\tlearn: 0.1386265\ttest: 0.1890264\tbest: 0.1890264 (419)\ttotal: 6m 13s\tremaining: 1m 11s\n",
            "420:\tlearn: 0.1385050\ttest: 0.1889285\tbest: 0.1889285 (420)\ttotal: 6m 14s\tremaining: 1m 10s\n",
            "421:\tlearn: 0.1383168\ttest: 0.1887988\tbest: 0.1887988 (421)\ttotal: 6m 15s\tremaining: 1m 9s\n",
            "422:\tlearn: 0.1380119\ttest: 0.1885863\tbest: 0.1885863 (422)\ttotal: 6m 16s\tremaining: 1m 8s\n",
            "423:\tlearn: 0.1379185\ttest: 0.1885199\tbest: 0.1885199 (423)\ttotal: 6m 17s\tremaining: 1m 7s\n",
            "424:\tlearn: 0.1378257\ttest: 0.1884462\tbest: 0.1884462 (424)\ttotal: 6m 18s\tremaining: 1m 6s\n",
            "425:\tlearn: 0.1377196\ttest: 0.1883801\tbest: 0.1883801 (425)\ttotal: 6m 19s\tremaining: 1m 5s\n",
            "426:\tlearn: 0.1376517\ttest: 0.1883338\tbest: 0.1883338 (426)\ttotal: 6m 20s\tremaining: 1m 4s\n",
            "427:\tlearn: 0.1375125\ttest: 0.1882160\tbest: 0.1882160 (427)\ttotal: 6m 20s\tremaining: 1m 4s\n",
            "428:\tlearn: 0.1374401\ttest: 0.1881743\tbest: 0.1881743 (428)\ttotal: 6m 21s\tremaining: 1m 3s\n",
            "429:\tlearn: 0.1371013\ttest: 0.1879055\tbest: 0.1879055 (429)\ttotal: 6m 22s\tremaining: 1m 2s\n",
            "430:\tlearn: 0.1368352\ttest: 0.1876502\tbest: 0.1876502 (430)\ttotal: 6m 23s\tremaining: 1m 1s\n",
            "431:\tlearn: 0.1366810\ttest: 0.1875315\tbest: 0.1875315 (431)\ttotal: 6m 23s\tremaining: 1m\n",
            "432:\tlearn: 0.1365632\ttest: 0.1874672\tbest: 0.1874672 (432)\ttotal: 6m 24s\tremaining: 59.5s\n",
            "433:\tlearn: 0.1364291\ttest: 0.1873663\tbest: 0.1873663 (433)\ttotal: 6m 25s\tremaining: 58.6s\n",
            "434:\tlearn: 0.1361812\ttest: 0.1871521\tbest: 0.1871521 (434)\ttotal: 6m 26s\tremaining: 57.7s\n",
            "435:\tlearn: 0.1360068\ttest: 0.1870173\tbest: 0.1870173 (435)\ttotal: 6m 27s\tremaining: 56.8s\n",
            "436:\tlearn: 0.1358596\ttest: 0.1869120\tbest: 0.1869120 (436)\ttotal: 6m 28s\tremaining: 55.9s\n",
            "437:\tlearn: 0.1357070\ttest: 0.1868175\tbest: 0.1868175 (437)\ttotal: 6m 29s\tremaining: 55.1s\n",
            "438:\tlearn: 0.1355067\ttest: 0.1866818\tbest: 0.1866818 (438)\ttotal: 6m 30s\tremaining: 54.3s\n",
            "439:\tlearn: 0.1353986\ttest: 0.1866195\tbest: 0.1866195 (439)\ttotal: 6m 31s\tremaining: 53.4s\n",
            "440:\tlearn: 0.1352420\ttest: 0.1864719\tbest: 0.1864719 (440)\ttotal: 6m 32s\tremaining: 52.5s\n",
            "441:\tlearn: 0.1351752\ttest: 0.1864320\tbest: 0.1864320 (441)\ttotal: 6m 32s\tremaining: 51.6s\n",
            "442:\tlearn: 0.1350963\ttest: 0.1863665\tbest: 0.1863665 (442)\ttotal: 6m 33s\tremaining: 50.7s\n",
            "443:\tlearn: 0.1349727\ttest: 0.1862493\tbest: 0.1862493 (443)\ttotal: 6m 34s\tremaining: 49.8s\n",
            "444:\tlearn: 0.1349084\ttest: 0.1862212\tbest: 0.1862212 (444)\ttotal: 6m 35s\tremaining: 48.9s\n",
            "445:\tlearn: 0.1348046\ttest: 0.1861508\tbest: 0.1861508 (445)\ttotal: 6m 36s\tremaining: 47.9s\n",
            "446:\tlearn: 0.1347469\ttest: 0.1861326\tbest: 0.1861326 (446)\ttotal: 6m 36s\tremaining: 47s\n",
            "447:\tlearn: 0.1345484\ttest: 0.1859307\tbest: 0.1859307 (447)\ttotal: 6m 37s\tremaining: 46.1s\n",
            "448:\tlearn: 0.1344070\ttest: 0.1858243\tbest: 0.1858243 (448)\ttotal: 6m 38s\tremaining: 45.2s\n",
            "449:\tlearn: 0.1343415\ttest: 0.1857912\tbest: 0.1857912 (449)\ttotal: 6m 39s\tremaining: 44.3s\n",
            "450:\tlearn: 0.1341349\ttest: 0.1856290\tbest: 0.1856290 (450)\ttotal: 6m 39s\tremaining: 43.4s\n",
            "451:\tlearn: 0.1339453\ttest: 0.1855132\tbest: 0.1855132 (451)\ttotal: 6m 40s\tremaining: 42.6s\n",
            "452:\tlearn: 0.1338162\ttest: 0.1854410\tbest: 0.1854410 (452)\ttotal: 6m 42s\tremaining: 41.7s\n",
            "453:\tlearn: 0.1335961\ttest: 0.1852473\tbest: 0.1852473 (453)\ttotal: 6m 43s\tremaining: 40.9s\n",
            "454:\tlearn: 0.1335369\ttest: 0.1852066\tbest: 0.1852066 (454)\ttotal: 6m 44s\tremaining: 40s\n",
            "455:\tlearn: 0.1332963\ttest: 0.1849703\tbest: 0.1849703 (455)\ttotal: 6m 45s\tremaining: 39.1s\n",
            "456:\tlearn: 0.1331313\ttest: 0.1848164\tbest: 0.1848164 (456)\ttotal: 6m 45s\tremaining: 38.2s\n",
            "457:\tlearn: 0.1329994\ttest: 0.1847288\tbest: 0.1847288 (457)\ttotal: 6m 46s\tremaining: 37.3s\n",
            "458:\tlearn: 0.1328983\ttest: 0.1846665\tbest: 0.1846665 (458)\ttotal: 6m 47s\tremaining: 36.4s\n",
            "459:\tlearn: 0.1326159\ttest: 0.1844356\tbest: 0.1844356 (459)\ttotal: 6m 48s\tremaining: 35.5s\n",
            "460:\tlearn: 0.1325356\ttest: 0.1843625\tbest: 0.1843625 (460)\ttotal: 6m 48s\tremaining: 34.6s\n",
            "461:\tlearn: 0.1323754\ttest: 0.1842611\tbest: 0.1842611 (461)\ttotal: 6m 49s\tremaining: 33.7s\n",
            "462:\tlearn: 0.1322970\ttest: 0.1842298\tbest: 0.1842298 (462)\ttotal: 6m 50s\tremaining: 32.8s\n",
            "463:\tlearn: 0.1322300\ttest: 0.1842180\tbest: 0.1842180 (463)\ttotal: 6m 51s\tremaining: 31.9s\n",
            "464:\tlearn: 0.1321153\ttest: 0.1841058\tbest: 0.1841058 (464)\ttotal: 6m 51s\tremaining: 31s\n",
            "465:\tlearn: 0.1319945\ttest: 0.1840136\tbest: 0.1840136 (465)\ttotal: 6m 52s\tremaining: 30.1s\n",
            "466:\tlearn: 0.1318741\ttest: 0.1839586\tbest: 0.1839586 (466)\ttotal: 6m 53s\tremaining: 29.2s\n",
            "467:\tlearn: 0.1317735\ttest: 0.1839202\tbest: 0.1839202 (467)\ttotal: 6m 54s\tremaining: 28.4s\n",
            "468:\tlearn: 0.1315836\ttest: 0.1837660\tbest: 0.1837660 (468)\ttotal: 6m 56s\tremaining: 27.5s\n",
            "469:\tlearn: 0.1314665\ttest: 0.1837063\tbest: 0.1837063 (469)\ttotal: 6m 57s\tremaining: 26.6s\n",
            "470:\tlearn: 0.1312446\ttest: 0.1834709\tbest: 0.1834709 (470)\ttotal: 6m 57s\tremaining: 25.7s\n",
            "471:\tlearn: 0.1310695\ttest: 0.1833633\tbest: 0.1833633 (471)\ttotal: 6m 58s\tremaining: 24.8s\n",
            "472:\tlearn: 0.1309708\ttest: 0.1832601\tbest: 0.1832601 (472)\ttotal: 6m 59s\tremaining: 23.9s\n",
            "473:\tlearn: 0.1308394\ttest: 0.1831402\tbest: 0.1831402 (473)\ttotal: 7m\tremaining: 23s\n",
            "474:\tlearn: 0.1306586\ttest: 0.1830254\tbest: 0.1830254 (474)\ttotal: 7m\tremaining: 22.2s\n",
            "475:\tlearn: 0.1306025\ttest: 0.1829773\tbest: 0.1829773 (475)\ttotal: 7m 1s\tremaining: 21.3s\n",
            "476:\tlearn: 0.1305129\ttest: 0.1829358\tbest: 0.1829358 (476)\ttotal: 7m 2s\tremaining: 20.4s\n",
            "477:\tlearn: 0.1303157\ttest: 0.1827727\tbest: 0.1827727 (477)\ttotal: 7m 3s\tremaining: 19.5s\n",
            "478:\tlearn: 0.1301672\ttest: 0.1826382\tbest: 0.1826382 (478)\ttotal: 7m 4s\tremaining: 18.6s\n",
            "479:\tlearn: 0.1299844\ttest: 0.1824868\tbest: 0.1824868 (479)\ttotal: 7m 4s\tremaining: 17.7s\n",
            "480:\tlearn: 0.1298714\ttest: 0.1824138\tbest: 0.1824138 (480)\ttotal: 7m 5s\tremaining: 16.8s\n",
            "481:\tlearn: 0.1296882\ttest: 0.1822693\tbest: 0.1822693 (481)\ttotal: 7m 6s\tremaining: 15.9s\n",
            "482:\tlearn: 0.1295941\ttest: 0.1822308\tbest: 0.1822308 (482)\ttotal: 7m 7s\tremaining: 15s\n",
            "483:\tlearn: 0.1294955\ttest: 0.1821620\tbest: 0.1821620 (483)\ttotal: 7m 8s\tremaining: 14.2s\n",
            "484:\tlearn: 0.1293855\ttest: 0.1820768\tbest: 0.1820768 (484)\ttotal: 7m 9s\tremaining: 13.3s\n",
            "485:\tlearn: 0.1292619\ttest: 0.1819587\tbest: 0.1819587 (485)\ttotal: 7m 10s\tremaining: 12.4s\n",
            "486:\tlearn: 0.1291287\ttest: 0.1818633\tbest: 0.1818633 (486)\ttotal: 7m 11s\tremaining: 11.5s\n",
            "487:\tlearn: 0.1290226\ttest: 0.1818100\tbest: 0.1818100 (487)\ttotal: 7m 12s\tremaining: 10.6s\n",
            "488:\tlearn: 0.1289411\ttest: 0.1817709\tbest: 0.1817709 (488)\ttotal: 7m 12s\tremaining: 9.74s\n",
            "489:\tlearn: 0.1287609\ttest: 0.1816400\tbest: 0.1816400 (489)\ttotal: 7m 13s\tremaining: 8.85s\n",
            "490:\tlearn: 0.1287120\ttest: 0.1816104\tbest: 0.1816104 (490)\ttotal: 7m 14s\tremaining: 7.96s\n",
            "491:\tlearn: 0.1285194\ttest: 0.1815066\tbest: 0.1815066 (491)\ttotal: 7m 15s\tremaining: 7.08s\n",
            "492:\tlearn: 0.1284579\ttest: 0.1814417\tbest: 0.1814417 (492)\ttotal: 7m 16s\tremaining: 6.19s\n",
            "493:\tlearn: 0.1283669\ttest: 0.1813561\tbest: 0.1813561 (493)\ttotal: 7m 16s\tremaining: 5.3s\n",
            "494:\tlearn: 0.1282801\ttest: 0.1813107\tbest: 0.1813107 (494)\ttotal: 7m 17s\tremaining: 4.42s\n",
            "495:\tlearn: 0.1282261\ttest: 0.1812483\tbest: 0.1812483 (495)\ttotal: 7m 18s\tremaining: 3.53s\n",
            "496:\tlearn: 0.1280334\ttest: 0.1811475\tbest: 0.1811475 (496)\ttotal: 7m 19s\tremaining: 2.65s\n",
            "497:\tlearn: 0.1279428\ttest: 0.1811133\tbest: 0.1811133 (497)\ttotal: 7m 19s\tremaining: 1.77s\n",
            "498:\tlearn: 0.1278089\ttest: 0.1810551\tbest: 0.1810551 (498)\ttotal: 7m 21s\tremaining: 884ms\n",
            "499:\tlearn: 0.1276658\ttest: 0.1809477\tbest: 0.1809477 (499)\ttotal: 7m 22s\tremaining: 0us\n",
            "\n",
            "bestTest = 0.180947726\n",
            "bestIteration = 499\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x79c80170c640>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.fit(X_train, y_train)\n",
        "y_predicted = model.predict(X_test)\n",
        "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_predicted)*100))\n",
        "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_predicted, labels=range(0,10))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyXgt5p8ntf9",
        "outputId": "facac5da-55d9-4ae5-94c2-e900f4c83219"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 95.84285714285714 %\n",
            "Classification Report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1373\n",
            "           1       0.98      0.99      0.98      1569\n",
            "           2       0.96      0.95      0.96      1430\n",
            "           3       0.95      0.96      0.95      1413\n",
            "           4       0.95      0.95      0.95      1376\n",
            "           5       0.96      0.95      0.95      1253\n",
            "           6       0.97      0.98      0.97      1339\n",
            "           7       0.96      0.95      0.96      1483\n",
            "           8       0.94      0.94      0.94      1365\n",
            "           9       0.94      0.93      0.93      1399\n",
            "\n",
            "    accuracy                           0.96     14000\n",
            "   macro avg       0.96      0.96      0.96     14000\n",
            "weighted avg       0.96      0.96      0.96     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Полносвязная нейронная сеть для классификации данных"
      ],
      "metadata": {
        "id": "g1VjkMZ-GxO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(32,\n",
        "                          input_dim=X_train.shape[1],\n",
        "                          activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "UYtJq-7HGw1k"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EK0s1HcG_PR",
        "outputId": "22a47d77-a543-4b48-ad50-ce83e07a5b5e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,458\n",
            "Trainable params: 4,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_labels = tf.keras.utils.to_categorical(y_train)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_R2jSktHvv8",
        "outputId": "4e076322-439d-46d9-9926-7bf8a3edc68d"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000,)\n",
            "(56000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train_labels,\n",
        "          batch_size=32, validation_split=0.2,\n",
        "          epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6shTaRMHZOh",
        "outputId": "2c605dbd-4384-4123-ca82-331b12a80c84"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1400/1400 [==============================] - 5s 3ms/step - loss: 18.7405 - accuracy: 0.7832 - val_loss: 5.0085 - val_accuracy: 0.8779\n",
            "Epoch 2/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 2.9428 - accuracy: 0.9108 - val_loss: 2.7082 - val_accuracy: 0.9083\n",
            "Epoch 3/10\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 1.6085 - accuracy: 0.9281 - val_loss: 2.0210 - val_accuracy: 0.9104\n",
            "Epoch 4/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 1.0389 - accuracy: 0.9371 - val_loss: 1.3483 - val_accuracy: 0.9254\n",
            "Epoch 5/10\n",
            "1400/1400 [==============================] - 4s 3ms/step - loss: 0.7529 - accuracy: 0.9407 - val_loss: 1.0401 - val_accuracy: 0.9246\n",
            "Epoch 6/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.5784 - accuracy: 0.9436 - val_loss: 0.8997 - val_accuracy: 0.9290\n",
            "Epoch 7/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.4561 - accuracy: 0.9479 - val_loss: 0.7535 - val_accuracy: 0.9253\n",
            "Epoch 8/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.3882 - accuracy: 0.9493 - val_loss: 0.6073 - val_accuracy: 0.9335\n",
            "Epoch 9/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.3409 - accuracy: 0.9494 - val_loss: 0.5863 - val_accuracy: 0.9333\n",
            "Epoch 10/10\n",
            "1400/1400 [==============================] - 3s 2ms/step - loss: 0.3068 - accuracy: 0.9500 - val_loss: 0.5368 - val_accuracy: 0.9352\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79c7ebabb520>"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred_labels = np.argmax(y_pred_proba, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFn_R7PJIUQM",
        "outputId": "93c237d8-0a1f-48bd-aed2-d756c575dc3e"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "438/438 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y_predicted = model.predict(X_test)\n",
        "print(\"Accuracy = {} %\".format(accuracy_score(y_test, y_pred_labels)*100))\n",
        "print(\"Classification Report \\n {}\".format(classification_report(y_test, y_pred_labels, labels=range(0,10))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAUDWcJ9IJxK",
        "outputId": "0c7f47cd-5995-480f-a0cd-a7470d88e298"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 94.81428571428572 %\n",
            "Classification Report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1373\n",
            "           1       0.98      0.98      0.98      1569\n",
            "           2       0.93      0.93      0.93      1430\n",
            "           3       0.92      0.95      0.93      1413\n",
            "           4       0.97      0.94      0.95      1376\n",
            "           5       0.94      0.91      0.93      1253\n",
            "           6       0.96      0.97      0.97      1339\n",
            "           7       0.94      0.97      0.96      1483\n",
            "           8       0.90      0.94      0.92      1365\n",
            "           9       0.96      0.91      0.94      1399\n",
            "\n",
            "    accuracy                           0.95     14000\n",
            "   macro avg       0.95      0.95      0.95     14000\n",
            "weighted avg       0.95      0.95      0.95     14000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Предсказания для Kaggle"
      ],
      "metadata": {
        "id": "1UZwWKaZuDZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_kaggle = pd.read_csv('/content/test.csv')"
      ],
      "metadata": {
        "id": "1tqb3jYJuKub"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_kaggle_imputed = imputer.fit_transform(X_kaggle)"
      ],
      "metadata": {
        "id": "u7qAJzyVmVsB"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_kaggle_pca = pca.fit_transform(X_kaggle_imputed)"
      ],
      "metadata": {
        "id": "tdUgWKy1vdS8"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = model.predict(X_kaggle_pca)"
      ],
      "metadata": {
        "id": "nLxm0t4LuZIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f9d737-93ca-49bf-aefa-feda0df64ba8"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "875/875 [==============================] - 4s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels = np.argmax(pred_test, axis=1)"
      ],
      "metadata": {
        "id": "tRs_piAlJFuE"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pred_test = np.ravel(pred_test).tolist()"
      ],
      "metadata": {
        "id": "SoII2knZDm3R"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJEGj9RR8lff"
      },
      "source": [
        "## Готовим файл для отправки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "collapsed": true,
        "id": "78qjWvjU8lff"
      },
      "outputs": [],
      "source": [
        "with open('submit.csv', 'w') as dst:\n",
        "    dst.write('ImageId,Label\\n')\n",
        "    for i, p in enumerate(y_pred_labels, 1):\n",
        "        dst.write('%s,%s\\n' % (i, p))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PwA2wBD8lfg",
        "outputId": "3db041b8-e494-4a5c-ca1f-20026f63b8dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ImageId,Label\n",
            "1,2\n",
            "2,0\n",
            "3,3\n",
            "4,2\n",
            "5,3\n",
            "6,2\n",
            "7,0\n",
            "8,9\n",
            "9,0\n"
          ]
        }
      ],
      "source": [
        "!head submit.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "fbo-bX6l8lfg"
      },
      "outputs": [],
      "source": [
        "# My submission scored 0.55807  Navie Bayes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}